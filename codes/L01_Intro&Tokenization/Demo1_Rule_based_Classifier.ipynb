{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Rule-based Sentiment Classifier\n",
        "\n",
        "This demo is a notebook with references from [CMU CS11-711 Advanced NLP](http://phontron.com/class/anlp2024/), in which you can attempt to build a rule-based sentiment classifier. It will take in a text `X` and return a `label` of \\\"1\\\" if the sentiment of the text is positive, \\\"-1\\\" if the sentiment of the text is negative, and \\\"0\\\" if the sentiment of the text is neutral. You can test the accuracy of your classifier on the [Stanford Sentiment Treebank](http://nlp.stanford.edu/sentiment/index.html) by running the notebook all the way to end.\n",
        "\n",
        "The only thing that you should change in this notebook is the following cell which contains two important elements. The first is `extract_features(X)`, which will extract a dictionary of (named) feature values from the text. You should create this by hand, and a simple example is shown for you. The second is `feature_weights`, a dictionary which will assign a weight to each extracted feature.\n",
        "\n",
        "The final way the classifier decides whether to assign a positive, negative, or neutral label is by calculating the dot product `feature_weights * extract_features(X)`, and if the value is greater than zero, return 1, less than zero return -1, and if exactly zero return 0.\n",
        "\n",
        "Let's have some fun trying to design a classifier 😁"
      ],
      "metadata": {
        "id": "nIEiktiOzhZw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTFd8XPHza2N"
      },
      "outputs": [],
      "source": [
        "def extract_features(x: str) -> dict[str, float]:\n",
        "    features = {}\n",
        "    x_split = x.split(' ')\n",
        "\n",
        "    # Count the number of \"good words\" and \"bad words\" in the text\n",
        "    good_words = ['love', 'good', 'nice', 'great', 'enjoy', 'enjoyed']\n",
        "    bad_words = ['hate', 'bad', 'terrible', 'disappointing', 'sad', 'lost', 'angry']\n",
        "    for x_word in x_split:\n",
        "        if x_word in good_words:\n",
        "            features['good_word_count'] = features.get('good_word_count', 0) + 1\n",
        "        if x_word in bad_words:\n",
        "            features['bad_word_count'] = features.get('bad_word_count', 0) + 1\n",
        "\n",
        "    # The \"bias\" value is always one, to allow us to assign a \"default\" score to the text\n",
        "    features['bias'] = 1\n",
        "\n",
        "    return features\n",
        "\n",
        "feature_weights = {'good_word_count': 1.0, 'bad_word_count': -1.0, 'bias': 0.5}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Reading\n",
        "\n",
        "Read in the data from the training and dev (or finally test) sets"
      ],
      "metadata": {
        "id": "0dqddog6z5lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/train.txt\n",
        "!wget https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zkfp7h0DJY",
        "outputId": "c8c543f0-96c5-485c-8ec3-74962ea6ebf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-01 12:23:09--  https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/train.txt\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/train.txt [following]\n",
            "--2025-01-01 12:23:09--  https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 940304 (918K) [text/plain]\n",
            "Saving to: ‘train.txt.1’\n",
            "\n",
            "\rtrain.txt.1           0%[                    ]       0  --.-KB/s               \rtrain.txt.1         100%[===================>] 918.27K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-01-01 12:23:09 (22.3 MB/s) - ‘train.txt.1’ saved [940304/940304]\n",
            "\n",
            "--2025-01-01 12:23:09--  https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt [following]\n",
            "--2025-01-01 12:23:10--  https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122071 (119K) [text/plain]\n",
            "Saving to: ‘dev.txt’\n",
            "\n",
            "dev.txt             100%[===================>] 119.21K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-01-01 12:23:10 (5.68 MB/s) - ‘dev.txt’ saved [122071/122071]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "    with open(filename, 'r') as f:\n",
        "        for line in f:\n",
        "            label, text = line.strip().split(' ||| ')\n",
        "            x_data.append(text)\n",
        "            y_data.append(int(label))\n",
        "    return x_data, y_data"
      ],
      "metadata": {
        "id": "3s6uFooCz4fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = read_xy_data('train.txt')\n",
        "x_test, y_test = read_xy_data('dev.txt')"
      ],
      "metadata": {
        "id": "TeiAsJlvz9ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4rWjl930NtC",
        "outputId": "779c8bbd-f014-48cf-e887-28096050161f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the Classifier and Calculate Accuracy\n",
        "\n",
        "Run the classifier over the training and dev (test) sets and calculate accuracy"
      ],
      "metadata": {
        "id": "AiepngMO0kU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_classifier(x: str) -> int:\n",
        "    score = 0\n",
        "    for feat_name, feat_value in extract_features(x).items():\n",
        "        score = score + feat_value * feature_weights.get(feat_name, 0)\n",
        "    if score > 0:\n",
        "        return 1\n",
        "    elif score < 0:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "DLjPYH_Q0iss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(x_data: list[str], y_data: list[int]) -> float:\n",
        "    total_number = 0\n",
        "    correct_number = 0\n",
        "    for x, y in zip(x_data, y_data):\n",
        "        y_pred = run_classifier(x)\n",
        "        total_number += 1\n",
        "        if y == y_pred:\n",
        "            correct_number += 1\n",
        "    return correct_number / float(total_number)"
      ],
      "metadata": {
        "id": "WWgzO83o0qDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_count = {}\n",
        "for y in y_test:\n",
        "    if y not in label_count:\n",
        "        label_count[y] = 0\n",
        "    label_count[y] += 1\n",
        "print(label_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdTZgDya0rMc",
        "outputId": "0728122a-067e-40d4-cc42-cb5f7f496e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 444, 0: 229, -1: 428}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calculate_accuracy(x_train, y_train)\n",
        "test_accuracy = calculate_accuracy(x_test, y_test)\n",
        "print(f'Train accuracy: {train_accuracy}')\n",
        "print(f'Dev/test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlijPYzW0tGl",
        "outputId": "b3b63357-ad44-48e5-b942-4cbad71f9b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.4345739700374532\n",
            "Dev/test accuracy: 0.4214350590372389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error Analysis\n",
        "\n",
        "An important part of improving any system is figuring out where it goes wrong. The following two functions allow you to randomly observe some mistaken examples, which may help you improve the classifier. Feel free to write more sophisticated methods for error analysis as well."
      ],
      "metadata": {
        "id": "SwcAYHU80x7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def find_errors(x_data, y_data):\n",
        "    error_ids = []\n",
        "    y_preds = []\n",
        "    for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
        "        y_preds.append(run_classifier(x))\n",
        "        if y != y_preds[-1]:\n",
        "            error_ids.append(i)\n",
        "    for _ in range(5):\n",
        "        my_id = random.choice(error_ids)\n",
        "        x, y, y_pred = x_data[my_id], y_data[my_id], y_preds[my_id]\n",
        "        print(f'{x}\\ntrue label: {y}\\npredicted label: {y_pred}\\n')"
      ],
      "metadata": {
        "id": "I7pOe7qN0xtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_errors(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QVPOQJA0uqF",
        "outputId": "97b2adae-a71a-4273-a412-96f23c741a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The problem is that Van Wilder does little that is actually funny with the material .\n",
            "true label: -1\n",
            "predicted label: 1\n",
            "\n",
            "It 's crap on a leash -- far too polite to scale the lunatic heights of Joe Dante 's similarly styled Gremlins .\n",
            "true label: -1\n",
            "predicted label: 1\n",
            "\n",
            "Like Rudy Yellow Lodge , Eyre needs to take a good sweat to clarify his cinematic vision before his next creation and remember the lessons of the trickster spider .\n",
            "true label: -1\n",
            "predicted label: 1\n",
            "\n",
            "Flawed , but worth seeing for Ambrose 's performance .\n",
            "true label: 0\n",
            "predicted label: 1\n",
            "\n",
            "Interview With the Assassin is structured less as a documentary and more as a found relic , and as such the film has a difficult time shaking its Blair Witch Project real-time roots .\n",
            "true label: -1\n",
            "predicted label: 1\n",
            "\n"
          ]
        }
      ]
    }
  ]
}